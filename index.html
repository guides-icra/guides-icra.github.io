<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <meta name="title" content="GUIDES: Guidance Using Instructor-Distilled Embeddings for Pre-trained Robot Policy Enhancement - Minquan Gao, Xinyi Li, Qing Yan, Xiaojian Sun, Xiaopan Zhang, Chien-Ming Huang, Jiachen Li">
  <meta name="description" content="A lightweight framework that augments pre-trained robot policies with semantic guidance from foundation models without requiring architectural redesign, offering a practical pathway to upgrade validated robot policies.">
  <meta name="keywords" content="robotics, pre-trained policies, vision-language models, semantic guidance, policy enhancement, foundation models, robot learning, machine learning, computer vision, AI">
  <meta name="author" content="Minquan Gao, Xinyi Li, Qing Yan, Xiaojian Sun, Xiaopan Zhang, Chien-Ming Huang, Jiachen Li">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="GUIDES: Guidance Using Instructor-Distilled Embeddings for Pre-trained Robot Policy Enhancement">
  <meta name="citation_author" content="Gao, Minquan">
  <meta name="citation_author" content="Li, Xinyi">
  <meta name="citation_author" content="Yan, Qing">
  <meta name="citation_author" content="Sun, Xiaojian">
  <meta name="citation_author" content="Zhang, Xiaopan">
  <meta name="citation_author" content="Huang, Chien-Ming">
  <meta name="citation_author" content="Li, Jiachen">
  <meta name="citation_publication_date" content="2026">
  <meta name="citation_conference_title" content="IEEE International Conference on Robotics and Automation (ICRA)">
  <meta name="citation_pdf_url" content="https://arxiv.org/pdf/2511.03400.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <title>GUIDES: Guidance Using Instructor-Distilled Embeddings for Pre-trained Robot Policy Enhancement - Minquan Gao, Xinyi Li, Qing Yan, Xiaojian Sun, Xiaopan Zhang, Chien-Ming Huang, Jiachen Li | Academic Research</title>
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/tasl.ico">
  <link rel="apple-touch-icon" href="static/images/tasl.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "GUIDES: Guidance Using Instructor-Distilled Embeddings for Pre-trained Robot Policy Enhancement",
    "description": "A lightweight framework that augments pre-trained robot policies with semantic guidance from foundation models without requiring architectural redesign, offering a practical pathway to upgrade validated robot policies.",
    "author": [
      {
        "@type": "Person",
        "name": "Minquan Gao",
        "affiliation": {
          "@type": "Organization",
          "name": "University of California, Riverside"
        }
      },
      {
        "@type": "Person",
        "name": "Xinyi Li",
        "affiliation": {
          "@type": "Organization",
          "name": "University of California, Riverside"
        }
      },
      {
        "@type": "Person",
        "name": "Qing Yan",
        "affiliation": {
          "@type": "Organization",
          "name": "University of California, Riverside"
        }
      },
      {
        "@type": "Person",
        "name": "Xiaojian Sun",
        "affiliation": {
          "@type": "Organization",
          "name": "University of California, Riverside"
        }
      },
      {
        "@type": "Person",
        "name": "Xiaopan Zhang",
        "affiliation": {
          "@type": "Organization",
          "name": "University of California, Riverside"
        }
      },
      {
        "@type": "Person",
        "name": "Chien-Ming Huang",
        "affiliation": {
          "@type": "Organization",
          "name": "Johns Hopkins University"
        }
      },
      {
        "@type": "Person",
        "name": "Jiachen Li",
        "affiliation": {
          "@type": "Organization",
          "name": "University of California, Riverside"
        }
      }
    ],
    "datePublished": "2026-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "IEEE International Conference on Robotics and Automation (ICRA)"
    },
    "url": "https://guides-icra.github.io/",
    "image": "https://guides-icra.github.io/static/images/social_preview.png",
    "keywords": ["robotics", "pre-trained policies", "vision-language models", "semantic guidance", "policy enhancement", "foundation models", "robot learning", "machine learning", "computer vision"],
    "abstract": "Pre-trained robot policies serve as the foundation of many validated robotic systems, which encapsulate extensive embodied knowledge. However, they often lack the semantic awareness characteristic of foundation models, and replacing them entirely is impractical in many situations due to high costs and the loss of accumulated knowledge. To address this gap, we introduce GUIDES, a lightweight framework that augments pre-trained policies with semantic guidance from foundation models without requiring architectural redesign. GUIDES employs a fine-tuned vision-language model (Instructor) to generate contextual instructions, which are encoded by an auxiliary module into guidance embeddings. These embeddings are injected into the policy's latent space, allowing the legacy model to adapt to this new semantic input through brief, targeted fine-tuning. For inference-time robustness, a large language model-based Reflector monitors the Instructor's confidence and, when confidence is low, initiates a reasoning loop that analyzes execution history, retrieves relevant examples, and augments the VLM's context to refine subsequent actions. Extensive validation in the RoboCasa simulation environment across diverse policy architectures shows consistent and substantial improvements in task success rates. Real-world deployment on a UR5 robot further demonstrates that GUIDES enhances motion precision for critical sub-tasks such as grasping. Overall, GUIDES offers a practical and resource-efficient pathway to upgrade, rather than replace, validated robot policies.",
    "citation": "@article{gao2025guides, title={GUIDES: Guidance Using Instructor-Distilled Embeddings for Pre-trained Robot Policy Enhancement}, author={Gao, Minquan and Li, Xinyi and Yan, Qing and Sun, Xiaojian and Zhang, Xiaopan and Huang, Chien-Ming and Li, Jiachen}, journal={IEEE International Conference on Robotics and Automation (ICRA)}, year={2026}}",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "University of California, Riverside",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/tasl.ico",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <!-- More Works Link -->
  <div style="position: fixed; top: 20px; right: 20px; z-index: 1000;">
    <a href="https://tasl.ucr.edu/publications/" target="_blank"
       class="external-link button is-normal is-rounded is-primary"
       style="font-weight: 500;">
      <span class="icon">
        <i class="fas fa-flask"></i>
      </span>
      <span>More Works</span>
    </a>
  </div>

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-widescreen">
        <div class="columns is-centered">
          <div class="column is-12 has-text-centered">
            <h1 class="title is-2 publication-title">GUIDES: Guidance Using Instructor-Distilled Embeddings<br><span class="is-size-4" style="font-style: italic; font-weight: 400; color: #666; font-family: 'Inter', sans-serif;">for Pre-trained Robot Policy Enhancement</span></h1>
            <div class="is-size-5" style="margin-top: 15px; margin-bottom: 20px;">
              <span style="font-weight: 600;">ICRA 2026, Rotterdam</span>
            </div>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="#" target="_blank">Minquan Gao</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="#" target="_blank">Xinyi Li</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="#" target="_blank">Qing Yan</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="#" target="_blank">Xiaojian Sun</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="#" target="_blank">Xiaopan Zhang</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="https://www.cs.jhu.edu/~cmhuang/" target="_blank">Chien-Ming Huang</a><sup>2</sup>,</span>
                  <span class="author-block">
                    <a href="https://jiachenli94.github.io/" target="_blank">Jiachen Li</a><sup>1*</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>University of California, Riverside &nbsp;&nbsp; <sup>2</sup>Johns Hopkins University</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Corresponding author</small></span>
                    <br>
                    <span class="author-block" style="display: flex; align-items: center; justify-content: center; gap: 8px;">
                      <img src="static/images/tasl.svg" alt="TASL Lab Logo" style="height: 20px; width: auto;">
                      <a href="https://tasl.ucr.edu/" target="_blank" style="font-weight: 500; color: #2563eb; text-decoration: underline;">
                        Trustworthy Autonomous Systems Laboratory (TASL)
                      </a>
                    </span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2511.03400.pdf"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <span class="link-block">
                    <a href="https://arxiv.org/abs/2511.03400"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>

                  <span class="link-block">
                    <a href="https://github.com/guides-icra/guides-icra.github.io"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-widescreen">
    <div class="hero-body">
      <h1 class="title is-3 has-text-centered" style="margin-bottom: 30px;">GUIDES: Enhancing Pre-trained Robot Policies with Semantic Guidance</h1>
      <!-- Video embed -->
      <div style="max-width: 100%; margin-bottom: 30px;">
        <video style="width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 16px rgba(0,0,0,0.1); display: block; margin: 0 auto;"
               controls
               preload="metadata">
          <source src="./static/videos/demo.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
      <!-- Qualitative results image -->
      <img src="static/images/qualitative.png" alt="Qualitative results showing RDD performance" style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 16px rgba(0,0,0,0.1); display: block; margin: 0 auto;">
      <h2 class="subtitle has-text-justified">
        Qualitative results of RDD and <a href="https://arxiv.org/pdf/2310.08581" target="_blank" style="color: #3273dc; text-decoration: underline;">UVD</a> when decomposing real-world and simulation benchmarks. RDD robustly identifies sub-tasks that are close to expert sub-task decompositions, while UVD fails to locate keyframes precisely.
      </h2>
      <!-- YouTube video embed -->
      <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; margin-bottom: 30px; border-radius: 8px; box-shadow: 0 4px 16px rgba(0,0,0,0.1);">
        <iframe
          style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border-radius: 8px;"
          src="https://www.youtube.com/embed/bwCgUyqdT6s"
          frameborder="0"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
          allowfullscreen>
        </iframe>
      </div>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-widescreen">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Pre-trained robot policies serve as the foundation of many validated robotic systems, which encapsulate extensive embodied knowledge. However, they often lack the semantic awareness characteristic of foundation models, and replacing them entirely is impractical in many situations due to high costs and the loss of accumulated knowledge. To address this gap, we introduce <strong>GUIDES</strong>, a lightweight framework that augments pre-trained policies with semantic guidance from foundation models without requiring architectural redesign. 
            <br><br>
            GUIDES employs a fine-tuned vision-language model (Instructor) to generate contextual instructions, which are encoded by an auxiliary module into guidance embeddings. These embeddings are injected into the policy's latent space, allowing the legacy model to adapt to this new semantic input through brief, targeted fine-tuning. For inference-time robustness, a large language model-based Reflector monitors the Instructor's confidence and, when confidence is low, initiates a reasoning loop that analyzes execution history, retrieves relevant examples, and augments the VLM's context to refine subsequent actions. 
            <br><br>
            Extensive validation in the RoboCasa simulation environment across diverse policy architectures shows consistent and substantial improvements in task success rates. Real-world deployment on a UR5 robot further demonstrates that GUIDES enhances motion precision for critical sub-tasks such as grasping. Overall, GUIDES offers a practical and resource-efficient pathway to upgrade, rather than replace, validated robot policies.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Method Overview Section -->
<section class="section">
  <div class="container is-max-widescreen">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">GUIDES Framework Overview</h2>
        <div class="content has-text-justified">
          <img src="static/images/teaser.png" alt="GUIDES framework overview" style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 16px rgba(0,0,0,0.1); display: block; margin: 0 auto 20px auto;"/>
          <p>
            <strong>The GUIDES Framework:</strong>
            GUIDES addresses the challenge of enhancing pre-trained robot policies with semantic awareness without requiring complete architectural redesign. The framework consists of three key components:
            <br><br>
            <strong>1. Instructor Module:</strong> A fine-tuned vision-language model that generates contextual instructions based on visual observations and task context.
            <br>
            <strong>2. Guidance Embedding Module:</strong> An auxiliary module that encodes the Instructor's instructions into guidance embeddings that can be injected into the policy's latent space.
            <br>
            <strong>3. Reflector Module:</strong> A large language model-based component that monitors the Instructor's confidence and initiates reasoning loops when needed to refine actions.
            <br><br>
            The framework allows legacy pre-trained policies to benefit from semantic guidance through targeted fine-tuning, offering a practical upgrade path without losing accumulated embodied knowledge.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End method overview -->

<!-- Method Architecture Section -->
<section class="section">
  <div class="container is-max-widescreen">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">GUIDES Architecture</h2>
        <div class="content has-text-justified">
          <img src="static/images/method.png" alt="GUIDES architecture and method overview" style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 16px rgba(0,0,0,0.1); display: block; margin: 0 auto 20px auto;"/>
          <p>
            The GUIDES architecture seamlessly integrates semantic guidance into pre-trained robot policies. The Instructor module processes visual observations to generate contextual instructions, which are then encoded into guidance embeddings and injected into the policy's latent space. The Reflector module provides inference-time robustness by monitoring confidence and initiating reasoning loops when needed.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End method architecture -->



<section class="section">
  <div class="container is-max-widescreen">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">
          Improves End-to-End Performance of Hierarchical VLA
        </h2></h2>
        <div class="content has-text-justified">
          <img src="static/images/main-results.png" alt="RDD method overview and architecture" style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 16px rgba(0,0,0,0.1); display: block; margin: 0 auto 20px auto;"/>
          <p>
           Results are averaged over 10 random seeds. RDD improves the end-to-end performance of the hierarchical VLA <a href="https://arxiv.org/pdf/2409.14674" target="_blank" style="color: #3273dc; text-decoration: underline;">RACER</a> and achieves a near-oracle performance and only compromises the success rate of merely 0.2% compared with the expert decomposer
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-widescreen">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">
          Real-World & Out-of-Distribution Demonstrations
        </h2></h2>
        <div class="content has-text-justified">
          <img src="static/images/realworld-ood.png" alt="rdd-realworld-ood" style="max-width: 40%; height: auto; border-radius: 8px; box-shadow: 0 4px 16px rgba(0,0,0,0.1); display: block; margin: 0 auto 20px auto;"/>
          <p>
           Performance (IoU) on <a href="https://huggingface.co/datasets/agibot-world/AgiBotWorld-Alpha" target="_blank" style="color: #3273dc; text-decoration: underline;">AgiBotWorld-Alpha</a> (real-world)
          and <a href="https://huggingface.co/datasets/qiukingballball/RoboCerebra" target="_blank" style="color: #3273dc; text-decoration: underline;">RoboCerebra</a> (out-of-distribution sub-tasks)
          </p>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-widescreen">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">
          Scalability
        </h2></h2>
        <div class="content has-text-justified">
          <img src="static/images/runtime_comparison.png" alt="speed" style="max-width: 40%; height: auto; border-radius: 8px; box-shadow: 0 4px 16px rgba(0,0,0,0.1); display: block; margin: 0 auto 20px auto;"/>
          <p>
           Linear time complexity of RDD with bounded maximum sub-task duration. Experiment uses a single CPU core (AMD EPYC 9254).
             We also provide a conceptual speed evaluation of RDD when working with the GPU-accelerated ANNS method <a href="https://github.com/facebookresearch/faiss" target="_blank" style="color: #3273dc; text-decoration: underline;">FAISS</a>. For details please refer to our paper.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>







<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@inproceedings{yan2025rdd,
  title={RDD: Retrieval-Based Demonstration Decomposer for Planner Alignment in Long-Horizon Tasks},
  author={Yan, Mingxuan and Wang, Yuping and Liu, Zechun and Li, Jiachen},
  booktitle={Proceedings of the 39th Annual Conference on Neural Information Processing Systems (NeurIPS)},
  year={2025},
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->




  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
